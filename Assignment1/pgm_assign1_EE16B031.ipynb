{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = './assignment-pgm-1/train.csv'\n",
    "test_file = './assignment-pgm-1/test.csv'\n",
    "submit_file = './assignment-pgm-1/submission.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since all are binary random variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NBfit(train_file):\n",
    "    \n",
    "    '''\n",
    "    Function to fit the data into naive bayes model and calculate CPDs\n",
    "    '''\n",
    "    \n",
    "    train_data = pd.read_csv(train_file)\n",
    "    print(\"Overview  of Training data : \\n {}\".format(train_data.head()))\n",
    "    \n",
    "    # separation of data into class 0 and 1\n",
    "    ind_0 = train_data['class']==0\n",
    "    # class labels\n",
    "    actual_classes = train_data['class']\n",
    "    del train_data['class']\n",
    "    #indexes of class 1.\n",
    "    ind_1 = ~ind_0\n",
    "    tr_data_0,tr_data_1 = train_data[ind_0].values,train_data[ind_1].values\n",
    "    \n",
    "    #calculation of probabilities\n",
    "    p_01  = (np.sum(tr_data_0,axis=0)+1)/(len(tr_data_0)+d)            #feature = 1 given class 0\n",
    "    p_11 = (np.sum(tr_data_1,axis=0)+1)/(len(tr_data_0)+d)             #feature = 1 given class 1\n",
    "\n",
    "    cpd_given_0 = np.log(p_01)\n",
    "    cpd_given_1 = np.log(p_11)\n",
    "\n",
    "    feat_cpds = pd.DataFrame([cpd_given_0,cpd_given_1],columns=train_data.columns)\n",
    "    \n",
    "    return feat_cpds,train_data,actual_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BNfit(train_file):\n",
    "    \n",
    "    '''\n",
    "    Function to fit the data into Bayesian Network\n",
    "    '''\n",
    "    \n",
    "    train_data = pd.read_csv(train_file)\n",
    "    print(\"Overview  of Training data : \\n {}\".format(train_data.head()))\n",
    "    \n",
    "    ind_0 = train_data['class']==0\n",
    "    actual_classes = train_data['class']\n",
    "    del train_data['class']\n",
    "    ind_1 = ~ind_0\n",
    "    tr_data_0,tr_data_1 = train_data[ind_0],train_data[ind_1]\n",
    "\n",
    "    #parent node for special dependency given\n",
    "    parents = ['V16']\n",
    "    # children nodes of the parent above\n",
    "    children = ['V8','V9']\n",
    "    \n",
    "    #indexes \n",
    "    ind_0_0 = (tr_data_0[parents[0]] == 0)            #v16 -> 0 and class 0\n",
    "    ind_0_1 = ~ind_0_0                                            #v16 -> 1 and class 0\n",
    "    ind_1_0 = (tr_data_1[parents[0]] == 0)            #v16 -> 0 and class 1\n",
    "    ind_1_1 = ~ind_1_0                                            #v16 -> 1 and class 1\n",
    "\n",
    "    feat_dep_cpds = []\n",
    "    \n",
    "    #calc of log probabs for 4 different params for v8 and v9.\n",
    "    feat_dep_cpds.append(np.log((np.sum(tr_data_0[children][ind_0_0],axis=0)+1)/(len(tr_data_0[children][ind_0_0])+d)))\n",
    "    feat_dep_cpds.append(np.log((np.sum(tr_data_0[children][ind_0_1],axis=0)+1)/(len(tr_data_0[children][ind_0_1])+d)))\n",
    "    feat_dep_cpds.append(np.log((np.sum(tr_data_1[children][ind_1_0],axis=0)+1)/(len(tr_data_1[children][ind_1_0])+d)))\n",
    "    feat_dep_cpds.append(np.log((np.sum(tr_data_1[children][ind_1_1],axis=0)+1)/(len(tr_data_1[children][ind_1_1])+d)))\n",
    "      \n",
    "    # deleting the children node from dataframe to find normal probab for other features.\n",
    "    for node in children:\n",
    "        del tr_data_0[node]\n",
    "        del tr_data_1[node]\n",
    "        \n",
    "    #log probab for features other than v8,v9\n",
    "    cpd_given_0 = np.log((np.sum(tr_data_0.values,axis=0)+1)/(len(tr_data_0)+d))\n",
    "    cpd_given_1 = np.log((np.sum(tr_data_1.values,axis=0)+1)/(len(tr_data_1)+d))\n",
    "    \n",
    "    cols = list(train_data.columns)\n",
    "    for child in children:\n",
    "        del cols[cols.index(child)]\n",
    "        \n",
    "    feat_normal_cpds = pd.DataFrame([cpd_given_0,cpd_given_1],columns=cols)\n",
    "    feat_dep_cpds = pd.DataFrame(feat_dep_cpds,columns=children)\n",
    "    \n",
    "    return feat_normal_cpds,feat_dep_cpds,children,parents,train_data,actual_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NBeval(file,feat_cpds,submit_file=None):\n",
    "    \n",
    "    '''\n",
    "    Function to predict the class of given sample using naive bayes cpds.\n",
    "    '''\n",
    "    \n",
    "    data = pd.read_csv(file)\n",
    "    pred_classes = pd.DataFrame(index=np.arange(len(data)),columns=['id','class'])\n",
    "     \n",
    "    if 'id' in data.columns: \n",
    "        del data['id']\n",
    "    else:\n",
    "        del data['class']    \n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "\n",
    "        pr_sample_0 = np.log(0.5)\n",
    "        pr_sample_1 = np.log(0.5)\n",
    "        \n",
    "        for j,x in enumerate(data.iloc[i,:]):\n",
    "            if (x==1): \n",
    "                pr_sample_0 += feat_cpds.iloc[0,j]\n",
    "                pr_sample_1 += feat_cpds.iloc[1,j]\n",
    "            else:\n",
    "                pr_sample_0 += np.log(1-np.exp(feat_cpds.iloc[0,j]))\n",
    "                pr_sample_1 += np.log(1-np.exp(feat_cpds.iloc[1,j]))\n",
    "\n",
    "            pred_classes.iloc[i,0] = i+1\n",
    "            \n",
    "            #assigning class labels based on log probabs\n",
    "            # Break tie when they are equal\n",
    "            if(pr_sample_1>=pr_sample_0):\n",
    "                pred_classes.iloc[i,1] = 1\n",
    "            else:\n",
    "                pred_classes.iloc[i,1] = 0\n",
    "    \n",
    "    if(submit_file is not None):\n",
    "        pred_classes.to_csv(path_or_buf=submit_file,index=False)\n",
    "    \n",
    "    return pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BNeval(file,feat_normal_cpds,feat_dep_cpds,children,parents,submit_file=None):\n",
    "\n",
    "    '''\n",
    "    Function to predict the class of given sample using Bayesian network cpds.\n",
    "    feat_normal_cpds - stores log probab of features other than v8 , v9\n",
    "    feat_dep_cpds  - stores log prob for v8 and v9.\n",
    "    '''\n",
    "    \n",
    "    data = pd.read_csv(file)\n",
    "    pred_classes = pd.DataFrame(index=np.arange(len(data)),columns=['id','class'])\n",
    "    \n",
    "    if 'id' in data.columns: \n",
    "        del data['id']\n",
    "    else:\n",
    "        del data['class']\n",
    "        \n",
    "    for i in range(data.shape[0]):\n",
    "\n",
    "        #prior probabilities\n",
    "        pr_sample_0 = np.log(0.5)\n",
    "        pr_sample_1 = np.log(0.5)\n",
    "        \n",
    "        for j,x in enumerate(data.iloc[i,:]):\n",
    "            curr_col = data.columns[j]\n",
    "\n",
    "            if(curr_col in children):\n",
    "\n",
    "                if(data.loc[i,parents[0]]==1):\n",
    "                    if (x==1):\n",
    "                        pr_sample_0 += feat_dep_cpds.loc[1,curr_col]\n",
    "                        pr_sample_1  += feat_dep_cpds.loc[3,curr_col]\n",
    "                    else:\n",
    "                        pr_sample_0 += np.log(1-np.exp(feat_dep_cpds.loc[1,curr_col]))\n",
    "                        pr_sample_1  += np.log(1-np.exp(feat_dep_cpds.loc[3,curr_col]))\n",
    "                else:\n",
    "                    if(x==1):\n",
    "                        pr_sample_0 += (feat_dep_cpds.loc[0,curr_col])\n",
    "                        pr_sample_1 += feat_dep_cpds.loc[2,curr_col]\n",
    "                    else:\n",
    "                        pr_sample_0 += np.log(1-np.exp(feat_dep_cpds.loc[0,curr_col]))\n",
    "                        pr_sample_1 += np.log(1-np.exp(feat_dep_cpds.loc[2,curr_col]))\n",
    "            else:\n",
    "                if(x==1):\n",
    "                    pr_sample_0 += feat_normal_cpds.loc[0,curr_col]\n",
    "                    pr_sample_1 += feat_normal_cpds.loc[1,curr_col]\n",
    "                else:\n",
    "                    pr_sample_0 += np.log(1-np.exp(feat_normal_cpds.loc[0,curr_col]))\n",
    "                    pr_sample_1 += np.log(1-np.exp(feat_normal_cpds.loc[1,curr_col]))\n",
    "                      \n",
    "            pred_classes.iloc[i,0] = i+1\n",
    "\n",
    "            # Break tie when they are equal\n",
    "            if(pr_sample_1>=pr_sample_0):\n",
    "                pred_classes.iloc[i,1] = 1\n",
    "            else:\n",
    "                pred_classes.iloc[i,1] = 0\n",
    "\n",
    "        if (submit_file is not None):\n",
    "            pred_classes.to_csv(path_or_buf=submit_file,index=False)\n",
    "            \n",
    "    return pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(actual_classes,pred_classes):\n",
    "    '''\n",
    "    Function to calculate accuracy of a classifier when actual class labels are known.\n",
    "    '''\n",
    "    train_acc = np.sum(actual_classes == pred_classes)/(len(actual_classes))*100\n",
    "    print(train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Implementation\n",
    "* change 'train_file'  into 'test_file' to run the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview  of Training data : \n",
      "    class  V1  V2  V3  V4  V5  V6  V7  V8  V9 ...   V13  V14  V15  V16  V17  \\\n",
      "0      1   0   0   0   1   0   0   0   1   1 ...     1    1    0    0    0   \n",
      "1      1   0   0   1   1   0   0   0   1   1 ...     1    1    0    0    0   \n",
      "2      1   1   0   1   0   1   0   0   1   0 ...     1    0    0    0    0   \n",
      "3      1   0   0   0   0   0   0   0   0   0 ...     0    0    0    0    0   \n",
      "4      1   0   0   0   0   0   0   0   1   0 ...     1    0    1    1    0   \n",
      "\n",
      "   V18  V19  V20  V21  V22  \n",
      "0    0    0    0    0    0  \n",
      "1    0    0    0    0    1  \n",
      "2    0    0    0    0    0  \n",
      "3    0    0    1    1    1  \n",
      "4    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Predicted classes distribution : \n",
      "0    49\n",
      "1    31\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "feat_cpds,train_data,actual_classes = NBfit(train_file)\n",
    "pred_classes = NBeval(train_file,feat_cpds=feat_cpds,submit_file=None)\n",
    "print(\"Predicted classes distribution : \\n{}\" .format(pred_classes['class'].value_counts()))\n",
    "nb_pred_classes = pred_classes['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.75\n"
     ]
    }
   ],
   "source": [
    "accuracy(actual_classes,pred_classes=nb_pred_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview  of Training data : \n",
      "    class  V1  V2  V3  V4  V5  V6  V7  V8  V9 ...   V13  V14  V15  V16  V17  \\\n",
      "0      1   0   0   0   1   0   0   0   1   1 ...     1    1    0    0    0   \n",
      "1      1   0   0   1   1   0   0   0   1   1 ...     1    1    0    0    0   \n",
      "2      1   1   0   1   0   1   0   0   1   0 ...     1    0    0    0    0   \n",
      "3      1   0   0   0   0   0   0   0   0   0 ...     0    0    0    0    0   \n",
      "4      1   0   0   0   0   0   0   0   1   0 ...     1    0    1    1    0   \n",
      "\n",
      "   V18  V19  V20  V21  V22  \n",
      "0    0    0    0    0    0  \n",
      "1    0    0    0    0    1  \n",
      "2    0    0    0    0    0  \n",
      "3    0    0    1    1    1  \n",
      "4    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Predicted classes distribution : \n",
      "0    47\n",
      "1    33\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "feat_normal_cpds,feat_dep_cpds,children,parents,train_data,actual_classes = BNfit(train_file)\n",
    "bn_pred_classes = BNeval(train_file,feat_normal_cpds,feat_dep_cpds,children=children,parents=parents,submit_file=None)\n",
    "print(\"Predicted classes distribution : \\n{}\" .format(bn_pred_classes['class'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.25\n"
     ]
    }
   ],
   "source": [
    "accuracy(actual_classes=actual_classes,pred_classes=bn_pred_classes['class'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.206897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V8        V9\n",
       "0  0.097561  0.097561\n",
       "1  0.666667  0.666667\n",
       "2  0.413793  0.206897\n",
       "3  0.533333  0.466667"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(feat_dep_cpds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  0.285714  0.095238  0.166667  0.119048  0.261905  0.095238  0.142857   \n",
       "1  0.452381  0.261905  0.380952  0.333333  0.357143  0.190476  0.404762   \n",
       "\n",
       "        V10       V11       V12       V13       V14       V15       V16  \\\n",
       "0  0.214286  0.095238  0.142857  0.142857  0.119048  0.047619  0.047619   \n",
       "1  0.380952  0.333333  0.380952  0.571429  0.309524  0.142857  0.333333   \n",
       "\n",
       "        V17       V18       V19       V20       V21       V22  \n",
       "0  0.023810  0.023810  0.142857  0.142857  0.119048  0.190476  \n",
       "1  0.214286  0.166667  0.261905  0.333333  0.380952  0.476190  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(feat_normal_cpds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding a better Bayesian Network\n",
    "To learn the structure from the given data,\n",
    "* We can find the correlation matrix of all the features.\n",
    "* Take the top $k$ correlated feature pairs, where $k$ is hyperparameter can be found using cross validation by splitting train data.\n",
    "* Since searching over the exponential no of possible BN structures blindly is not efficient, so we restrict this by using the correlation of features.\n",
    "* But since we don't know the causation still, we have to randomly choose which one has to be parent among the selected pairs.\n",
    "* By experimenting in this manner, we can achieve a better result than we got earlier. Due to time constraint, I couldn't implement it, but this is the idea I have in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_mat = train_data.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>0.234019</td>\n",
       "      <td>0.028956</td>\n",
       "      <td>0.042880</td>\n",
       "      <td>0.010601</td>\n",
       "      <td>0.193671</td>\n",
       "      <td>0.030063</td>\n",
       "      <td>0.030222</td>\n",
       "      <td>0.025633</td>\n",
       "      <td>0.019778</td>\n",
       "      <td>0.185601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036076</td>\n",
       "      <td>0.040506</td>\n",
       "      <td>0.010443</td>\n",
       "      <td>0.024367</td>\n",
       "      <td>0.026582</td>\n",
       "      <td>0.010443</td>\n",
       "      <td>0.095728</td>\n",
       "      <td>0.043987</td>\n",
       "      <td>0.026741</td>\n",
       "      <td>0.007278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>0.028956</td>\n",
       "      <td>0.137816</td>\n",
       "      <td>0.020095</td>\n",
       "      <td>-0.009652</td>\n",
       "      <td>0.039241</td>\n",
       "      <td>0.055380</td>\n",
       "      <td>0.096044</td>\n",
       "      <td>0.018038</td>\n",
       "      <td>0.019778</td>\n",
       "      <td>0.028639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005696</td>\n",
       "      <td>0.017722</td>\n",
       "      <td>-0.012342</td>\n",
       "      <td>0.059810</td>\n",
       "      <td>0.059494</td>\n",
       "      <td>0.050949</td>\n",
       "      <td>0.045095</td>\n",
       "      <td>0.026266</td>\n",
       "      <td>0.036867</td>\n",
       "      <td>0.035127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>0.042880</td>\n",
       "      <td>0.020095</td>\n",
       "      <td>0.196044</td>\n",
       "      <td>0.082753</td>\n",
       "      <td>0.008861</td>\n",
       "      <td>-0.007911</td>\n",
       "      <td>0.031487</td>\n",
       "      <td>0.142089</td>\n",
       "      <td>0.051424</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134810</td>\n",
       "      <td>0.073418</td>\n",
       "      <td>0.030696</td>\n",
       "      <td>0.067405</td>\n",
       "      <td>0.024051</td>\n",
       "      <td>0.030696</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.016139</td>\n",
       "      <td>0.101424</td>\n",
       "      <td>0.052848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>0.010601</td>\n",
       "      <td>-0.009652</td>\n",
       "      <td>0.082753</td>\n",
       "      <td>0.169462</td>\n",
       "      <td>-0.026582</td>\n",
       "      <td>-0.014241</td>\n",
       "      <td>-0.005854</td>\n",
       "      <td>0.054747</td>\n",
       "      <td>0.086234</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076582</td>\n",
       "      <td>0.096203</td>\n",
       "      <td>0.034494</td>\n",
       "      <td>0.050949</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.021835</td>\n",
       "      <td>-0.002373</td>\n",
       "      <td>0.014873</td>\n",
       "      <td>0.050158</td>\n",
       "      <td>0.043987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>0.193671</td>\n",
       "      <td>0.039241</td>\n",
       "      <td>0.008861</td>\n",
       "      <td>-0.026582</td>\n",
       "      <td>0.212658</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.034177</td>\n",
       "      <td>-0.007595</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.153165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.027848</td>\n",
       "      <td>-0.010127</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>0.032911</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.082278</td>\n",
       "      <td>0.045570</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.002532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>0.030063</td>\n",
       "      <td>0.055380</td>\n",
       "      <td>-0.007911</td>\n",
       "      <td>-0.014241</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.110759</td>\n",
       "      <td>0.017405</td>\n",
       "      <td>-0.009494</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.014241</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018987</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>-0.009494</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.050633</td>\n",
       "      <td>0.015823</td>\n",
       "      <td>0.064873</td>\n",
       "      <td>0.034810</td>\n",
       "      <td>-0.017405</td>\n",
       "      <td>-0.003165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>0.030222</td>\n",
       "      <td>0.096044</td>\n",
       "      <td>0.031487</td>\n",
       "      <td>-0.005854</td>\n",
       "      <td>0.034177</td>\n",
       "      <td>0.017405</td>\n",
       "      <td>0.196044</td>\n",
       "      <td>0.028165</td>\n",
       "      <td>0.026108</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020886</td>\n",
       "      <td>0.022785</td>\n",
       "      <td>0.005380</td>\n",
       "      <td>0.054747</td>\n",
       "      <td>0.049367</td>\n",
       "      <td>0.043354</td>\n",
       "      <td>0.038766</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.088766</td>\n",
       "      <td>0.065506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>0.025633</td>\n",
       "      <td>0.018038</td>\n",
       "      <td>0.142089</td>\n",
       "      <td>0.054747</td>\n",
       "      <td>-0.007595</td>\n",
       "      <td>-0.009494</td>\n",
       "      <td>0.028165</td>\n",
       "      <td>0.201899</td>\n",
       "      <td>0.061709</td>\n",
       "      <td>0.021203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117722</td>\n",
       "      <td>0.045570</td>\n",
       "      <td>0.042405</td>\n",
       "      <td>0.052532</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>0.017089</td>\n",
       "      <td>-0.001582</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.073101</td>\n",
       "      <td>0.010759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>0.019778</td>\n",
       "      <td>0.019778</td>\n",
       "      <td>0.051424</td>\n",
       "      <td>0.086234</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.026108</td>\n",
       "      <td>0.061709</td>\n",
       "      <td>0.154272</td>\n",
       "      <td>0.021361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047468</td>\n",
       "      <td>0.126582</td>\n",
       "      <td>0.036392</td>\n",
       "      <td>0.055380</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>0.027690</td>\n",
       "      <td>0.033228</td>\n",
       "      <td>0.043513</td>\n",
       "      <td>0.014241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>0.185601</td>\n",
       "      <td>0.028639</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.153165</td>\n",
       "      <td>0.014241</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.021203</td>\n",
       "      <td>0.021361</td>\n",
       "      <td>0.207437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037342</td>\n",
       "      <td>0.030380</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.012342</td>\n",
       "      <td>0.021519</td>\n",
       "      <td>-0.009177</td>\n",
       "      <td>0.071994</td>\n",
       "      <td>0.035759</td>\n",
       "      <td>0.032120</td>\n",
       "      <td>0.006646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>0.053165</td>\n",
       "      <td>0.068354</td>\n",
       "      <td>-0.002532</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.040506</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.060759</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.017722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007595</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>-0.002532</td>\n",
       "      <td>0.027848</td>\n",
       "      <td>0.055696</td>\n",
       "      <td>0.035443</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.017722</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.022785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>0.047468</td>\n",
       "      <td>0.085443</td>\n",
       "      <td>0.034810</td>\n",
       "      <td>0.022152</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.031646</td>\n",
       "      <td>0.148734</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.015823</td>\n",
       "      <td>0.041139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050633</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>-0.006329</td>\n",
       "      <td>0.056962</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.056962</td>\n",
       "      <td>0.041139</td>\n",
       "      <td>0.031646</td>\n",
       "      <td>0.079114</td>\n",
       "      <td>0.069620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>0.036076</td>\n",
       "      <td>0.005696</td>\n",
       "      <td>0.134810</td>\n",
       "      <td>0.076582</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>-0.018987</td>\n",
       "      <td>0.020886</td>\n",
       "      <td>0.117722</td>\n",
       "      <td>0.047468</td>\n",
       "      <td>0.037342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230380</td>\n",
       "      <td>0.068354</td>\n",
       "      <td>0.036709</td>\n",
       "      <td>0.077215</td>\n",
       "      <td>0.027848</td>\n",
       "      <td>0.036709</td>\n",
       "      <td>-0.015823</td>\n",
       "      <td>0.046835</td>\n",
       "      <td>0.093038</td>\n",
       "      <td>0.074684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>0.040506</td>\n",
       "      <td>0.017722</td>\n",
       "      <td>0.073418</td>\n",
       "      <td>0.096203</td>\n",
       "      <td>0.027848</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.022785</td>\n",
       "      <td>0.045570</td>\n",
       "      <td>0.126582</td>\n",
       "      <td>0.030380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068354</td>\n",
       "      <td>0.162025</td>\n",
       "      <td>0.022785</td>\n",
       "      <td>0.065823</td>\n",
       "      <td>0.005063</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0.053165</td>\n",
       "      <td>0.022785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>0.010443</td>\n",
       "      <td>-0.012342</td>\n",
       "      <td>0.030696</td>\n",
       "      <td>0.034494</td>\n",
       "      <td>-0.010127</td>\n",
       "      <td>-0.009494</td>\n",
       "      <td>0.005380</td>\n",
       "      <td>0.042405</td>\n",
       "      <td>0.036392</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036709</td>\n",
       "      <td>0.022785</td>\n",
       "      <td>0.070253</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.007595</td>\n",
       "      <td>0.006962</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>0.008228</td>\n",
       "      <td>0.019937</td>\n",
       "      <td>0.013291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>0.024367</td>\n",
       "      <td>0.059810</td>\n",
       "      <td>0.067405</td>\n",
       "      <td>0.050949</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.054747</td>\n",
       "      <td>0.052532</td>\n",
       "      <td>0.055380</td>\n",
       "      <td>0.012342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077215</td>\n",
       "      <td>0.065823</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>0.146203</td>\n",
       "      <td>0.032911</td>\n",
       "      <td>0.062658</td>\n",
       "      <td>0.030063</td>\n",
       "      <td>0.048734</td>\n",
       "      <td>0.059177</td>\n",
       "      <td>0.056329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>0.026582</td>\n",
       "      <td>0.059494</td>\n",
       "      <td>0.024051</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.032911</td>\n",
       "      <td>0.050633</td>\n",
       "      <td>0.049367</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.021519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027848</td>\n",
       "      <td>0.005063</td>\n",
       "      <td>-0.007595</td>\n",
       "      <td>0.032911</td>\n",
       "      <td>0.091139</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0.044304</td>\n",
       "      <td>0.040506</td>\n",
       "      <td>0.013924</td>\n",
       "      <td>0.030380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>0.010443</td>\n",
       "      <td>0.050949</td>\n",
       "      <td>0.030696</td>\n",
       "      <td>0.021835</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.015823</td>\n",
       "      <td>0.043354</td>\n",
       "      <td>0.017089</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>-0.009177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036709</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>0.006962</td>\n",
       "      <td>0.062658</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0.070253</td>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.020886</td>\n",
       "      <td>0.032595</td>\n",
       "      <td>0.051266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>0.095728</td>\n",
       "      <td>0.045095</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>-0.002373</td>\n",
       "      <td>0.082278</td>\n",
       "      <td>0.064873</td>\n",
       "      <td>0.038766</td>\n",
       "      <td>-0.001582</td>\n",
       "      <td>0.027690</td>\n",
       "      <td>0.071994</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015823</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>0.030063</td>\n",
       "      <td>0.044304</td>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.154272</td>\n",
       "      <td>0.045886</td>\n",
       "      <td>-0.019778</td>\n",
       "      <td>-0.011076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>0.043987</td>\n",
       "      <td>0.026266</td>\n",
       "      <td>0.016139</td>\n",
       "      <td>0.014873</td>\n",
       "      <td>0.045570</td>\n",
       "      <td>0.034810</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.033228</td>\n",
       "      <td>0.035759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046835</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0.008228</td>\n",
       "      <td>0.048734</td>\n",
       "      <td>0.040506</td>\n",
       "      <td>0.020886</td>\n",
       "      <td>0.045886</td>\n",
       "      <td>0.176582</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>0.027215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>0.026741</td>\n",
       "      <td>0.036867</td>\n",
       "      <td>0.101424</td>\n",
       "      <td>0.050158</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>-0.017405</td>\n",
       "      <td>0.088766</td>\n",
       "      <td>0.073101</td>\n",
       "      <td>0.043513</td>\n",
       "      <td>0.032120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093038</td>\n",
       "      <td>0.053165</td>\n",
       "      <td>0.019937</td>\n",
       "      <td>0.059177</td>\n",
       "      <td>0.013924</td>\n",
       "      <td>0.032595</td>\n",
       "      <td>-0.019778</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>0.183386</td>\n",
       "      <td>0.073734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>0.007278</td>\n",
       "      <td>0.035127</td>\n",
       "      <td>0.052848</td>\n",
       "      <td>0.043987</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.003165</td>\n",
       "      <td>0.065506</td>\n",
       "      <td>0.010759</td>\n",
       "      <td>0.014241</td>\n",
       "      <td>0.006646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074684</td>\n",
       "      <td>0.022785</td>\n",
       "      <td>0.013291</td>\n",
       "      <td>0.056329</td>\n",
       "      <td>0.030380</td>\n",
       "      <td>0.051266</td>\n",
       "      <td>-0.011076</td>\n",
       "      <td>0.027215</td>\n",
       "      <td>0.073734</td>\n",
       "      <td>0.222152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           V1        V2        V3        V4        V5        V6        V7  \\\n",
       "V1   0.234019  0.028956  0.042880  0.010601  0.193671  0.030063  0.030222   \n",
       "V2   0.028956  0.137816  0.020095 -0.009652  0.039241  0.055380  0.096044   \n",
       "V3   0.042880  0.020095  0.196044  0.082753  0.008861 -0.007911  0.031487   \n",
       "V4   0.010601 -0.009652  0.082753  0.169462 -0.026582 -0.014241 -0.005854   \n",
       "V5   0.193671  0.039241  0.008861 -0.026582  0.212658  0.037975  0.034177   \n",
       "V6   0.030063  0.055380 -0.007911 -0.014241  0.037975  0.110759  0.017405   \n",
       "V7   0.030222  0.096044  0.031487 -0.005854  0.034177  0.017405  0.196044   \n",
       "V8   0.025633  0.018038  0.142089  0.054747 -0.007595 -0.009494  0.028165   \n",
       "V9   0.019778  0.019778  0.051424  0.086234  0.006329  0.001582  0.026108   \n",
       "V10  0.185601  0.028639  0.037500  0.001424  0.153165  0.014241  0.037500   \n",
       "V11  0.053165  0.068354 -0.002532  0.007595  0.040506  0.063291  0.060759   \n",
       "V12  0.047468  0.085443  0.034810  0.022152  0.037975  0.031646  0.148734   \n",
       "V13  0.036076  0.005696  0.134810  0.076582  0.007595 -0.018987  0.020886   \n",
       "V14  0.040506  0.017722  0.073418  0.096203  0.027848  0.012658  0.022785   \n",
       "V15  0.010443 -0.012342  0.030696  0.034494 -0.010127 -0.009494  0.005380   \n",
       "V16  0.024367  0.059810  0.067405  0.050949  0.010127  0.003165  0.054747   \n",
       "V17  0.026582  0.059494  0.024051  0.003797  0.032911  0.050633  0.049367   \n",
       "V18  0.010443  0.050949  0.030696  0.021835  0.002532  0.015823  0.043354   \n",
       "V19  0.095728  0.045095  0.000791 -0.002373  0.082278  0.064873  0.038766   \n",
       "V20  0.043987  0.026266  0.016139  0.014873  0.045570  0.034810  0.003481   \n",
       "V21  0.026741  0.036867  0.101424  0.050158  0.003797 -0.017405  0.088766   \n",
       "V22  0.007278  0.035127  0.052848  0.043987  0.002532 -0.003165  0.065506   \n",
       "\n",
       "           V8        V9       V10    ...          V13       V14       V15  \\\n",
       "V1   0.025633  0.019778  0.185601    ...     0.036076  0.040506  0.010443   \n",
       "V2   0.018038  0.019778  0.028639    ...     0.005696  0.017722 -0.012342   \n",
       "V3   0.142089  0.051424  0.037500    ...     0.134810  0.073418  0.030696   \n",
       "V4   0.054747  0.086234  0.001424    ...     0.076582  0.096203  0.034494   \n",
       "V5  -0.007595  0.006329  0.153165    ...     0.007595  0.027848 -0.010127   \n",
       "V6  -0.009494  0.001582  0.014241    ...    -0.018987  0.012658 -0.009494   \n",
       "V7   0.028165  0.026108  0.037500    ...     0.020886  0.022785  0.005380   \n",
       "V8   0.201899  0.061709  0.021203    ...     0.117722  0.045570  0.042405   \n",
       "V9   0.061709  0.154272  0.021361    ...     0.047468  0.126582  0.036392   \n",
       "V10  0.021203  0.021361  0.207437    ...     0.037342  0.030380  0.003481   \n",
       "V11  0.007595  0.012658  0.017722    ...    -0.007595  0.010127 -0.002532   \n",
       "V12  0.006329  0.015823  0.041139    ...     0.050633  0.025316 -0.006329   \n",
       "V13  0.117722  0.047468  0.037342    ...     0.230380  0.068354  0.036709   \n",
       "V14  0.045570  0.126582  0.030380    ...     0.068354  0.162025  0.022785   \n",
       "V15  0.042405  0.036392  0.003481    ...     0.036709  0.022785  0.070253   \n",
       "V16  0.052532  0.055380  0.012342    ...     0.077215  0.065823  0.024684   \n",
       "V17  0.010127  0.006329  0.021519    ...     0.027848  0.005063 -0.007595   \n",
       "V18  0.017089  0.011076 -0.009177    ...     0.036709  0.010127  0.006962   \n",
       "V19 -0.001582  0.027690  0.071994    ...    -0.015823  0.037975  0.011076   \n",
       "V20  0.000633  0.033228  0.035759    ...     0.046835  0.043038  0.008228   \n",
       "V21  0.073101  0.043513  0.032120    ...     0.093038  0.053165  0.019937   \n",
       "V22  0.010759  0.014241  0.006646    ...     0.074684  0.022785  0.013291   \n",
       "\n",
       "          V16       V17       V18       V19       V20       V21       V22  \n",
       "V1   0.024367  0.026582  0.010443  0.095728  0.043987  0.026741  0.007278  \n",
       "V2   0.059810  0.059494  0.050949  0.045095  0.026266  0.036867  0.035127  \n",
       "V3   0.067405  0.024051  0.030696  0.000791  0.016139  0.101424  0.052848  \n",
       "V4   0.050949  0.003797  0.021835 -0.002373  0.014873  0.050158  0.043987  \n",
       "V5   0.010127  0.032911  0.002532  0.082278  0.045570  0.003797  0.002532  \n",
       "V6   0.003165  0.050633  0.015823  0.064873  0.034810 -0.017405 -0.003165  \n",
       "V7   0.054747  0.049367  0.043354  0.038766  0.003481  0.088766  0.065506  \n",
       "V8   0.052532  0.010127  0.017089 -0.001582  0.000633  0.073101  0.010759  \n",
       "V9   0.055380  0.006329  0.011076  0.027690  0.033228  0.043513  0.014241  \n",
       "V10  0.012342  0.021519 -0.009177  0.071994  0.035759  0.032120  0.006646  \n",
       "V11  0.027848  0.055696  0.035443  0.075949  0.017722  0.015190  0.022785  \n",
       "V12  0.056962  0.063291  0.056962  0.041139  0.031646  0.079114  0.069620  \n",
       "V13  0.077215  0.027848  0.036709 -0.015823  0.046835  0.093038  0.074684  \n",
       "V14  0.065823  0.005063  0.010127  0.037975  0.043038  0.053165  0.022785  \n",
       "V15  0.024684 -0.007595  0.006962  0.011076  0.008228  0.019937  0.013291  \n",
       "V16  0.146203  0.032911  0.062658  0.030063  0.048734  0.059177  0.056329  \n",
       "V17  0.032911  0.091139  0.043038  0.044304  0.040506  0.013924  0.030380  \n",
       "V18  0.062658  0.043038  0.070253  0.023734  0.020886  0.032595  0.051266  \n",
       "V19  0.030063  0.044304  0.023734  0.154272  0.045886 -0.019778 -0.011076  \n",
       "V20  0.048734  0.040506  0.020886  0.045886  0.176582  0.009177  0.027215  \n",
       "V21  0.059177  0.013924  0.032595 -0.019778  0.009177  0.183386  0.073734  \n",
       "V22  0.056329  0.030380  0.051266 -0.011076  0.027215  0.073734  0.222152  \n",
       "\n",
       "[22 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top correlated features w.r.t V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V5', 'V10', 'V19', 'V11', 'V12', 'V20', 'V3', 'V14', 'V13', 'V7',\n",
       "       'V6', 'V2', 'V21', 'V17', 'V8', 'V16', 'V9', 'V4', 'V18', 'V15', 'V22'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns[np.argsort(cov_mat.values,axis=-1)[0][::-1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
